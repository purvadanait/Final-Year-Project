{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP60Es2Xiu/f8oJfU/8o7j9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purvadanait/Final-Year-Project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi\n",
        "!pip install python-utils\n",
        "!pip install python-multipart"
      ],
      "metadata": {
        "id": "gMiTpnJ6AFKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f0af79-bba6-4d53-f478-49578caf5cd3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.8/dist-packages (0.88.0)\n",
            "Requirement already satisfied: starlette==0.22.0 in /usr/local/lib/python3.8/dist-packages (from fastapi) (0.22.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from fastapi) (1.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi) (4.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi) (3.6.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.8/dist-packages (3.4.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from python-multipart) (1.15.0)\n",
            "Building wheels for collected packages: python-multipart\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=51074205b3ada317fc169c869e6cbb7571f6570de968185efa553a0b9632a21a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built python-multipart\n",
            "Installing collected packages: python-multipart\n",
            "Successfully installed python-multipart-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pK3bKCEcIEx",
        "outputId": "267c00c4-10df-41fa-8016-2bb0276f19a9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/inference_utils.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox6BtQJXcO9A",
        "outputId": "ed34346f-30a6-4834-cf10-8a2262e81d35"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/My Drive/inference_utils.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/drive/My Drive/inference_utils.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKH7YsMdc9tA",
        "outputId": "8c066fb0-5cc1-4a60-bf8a-37bdf4ef1f9e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"inference_utils.ipynb\n",
            "\n",
            "Automatically generated by Colaboratory.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1-E0roVmceQ6ODYmZ6E7nw0D7pigppn0W\n",
            "\"\"\"\n",
            "\n",
            "from google.colab import drive\n",
            "drive.mount('/content/drive', force_remount=True)\n",
            "\n",
            "import sys\n",
            "sys.path.append(\"/content/drive/My Drive\")\n",
            "\n",
            "import cv2_utils\n",
            "\n",
            "import sys\n",
            "sys.path.append(\"/content/drive/My Drive\")\n",
            "\n",
            "import deep_crack\n",
            "\n",
            "import os\n",
            "import cv2\n",
            "import torch\n",
            "import numpy as np\n",
            "from PIL import Image\n",
            "from io import BytesIO\n",
            "from cv2_utils import getContours\n",
            "import torchvision.transforms as transforms\n",
            "from deep_crack import DeepCrack\n",
            "\n",
            "def tensor2im(input_image, imtype=np.uint8):\n",
            "    \"\"\"\"Converts a Tensor array into a numpy image array.\n",
            "    Parameters:\n",
            "        input_image (tensor) --  the input image tensor array\n",
            "        imtype (type)        --  the desired type of the converted numpy array\n",
            "    \"\"\"\n",
            "    if not isinstance(input_image, np.ndarray):\n",
            "        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n",
            "            image_tensor = input_image.data\n",
            "        else:\n",
            "            return input_image\n",
            "        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n",
            "        if image_numpy.shape[0] == 1:  # grayscale to RGB\n",
            "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
            "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n",
            "    else:  # if it is a numpy array, do nothing\n",
            "        image_numpy = input_image\n",
            "    return image_numpy.astype(imtype)\n",
            "\n",
            "def bytes_to_array(b: bytes) -> np.ndarray:\n",
            "    np_bytes = BytesIO(b)\n",
            "    return np.load(np_bytes, allow_pickle=True)\n",
            "\n",
            "def read_image(bytesImg, dim=(256, 256)):    #Decode Bytes to array\n",
            "    img_transforms = transforms.Compose([transforms.ToTensor(),\n",
            "                                                transforms.Normalize((0.5, 0.5, 0.5),\n",
            "                                                                       (0.5, 0.5, 0.5))])\n",
            "    img = np.fromstring(bytesImg, np.uint8)\n",
            "    img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
            "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
            "    \n",
            "    # adjust the image size\n",
            "    w, h = dim\n",
            "    if w > 0 or h > 0:\n",
            "        img = cv2.resize(img, (w, h), interpolation=cv2.INTER_CUBIC)\n",
            "    \n",
            "    # apply the transform to both A and B\n",
            "    img = img_transforms(Image.fromarray(img.copy()))   \n",
            "    return img\n",
            "\n",
            "def create_model(opt, cp_path='pretrained_net_G.pth'):\n",
            "    model = DeepCrackModel(opt)      # create a model given opt.model and other options\n",
            "    checkpoint = torch.load(cp_path)\n",
            "    if hasattr(model.netG, 'module'):\n",
            "        model.netG.module.load_state_dict(checkpoint, strict=False)\n",
            "    else:\n",
            "        model.netG.load_state_dict(checkpoint, strict=False)\n",
            "    model.eval()\n",
            "    return model\n",
            "\n",
            "def overlay(\n",
            "    image: np.ndarray,\n",
            "    mask: np.ndarray,\n",
            "    color = (255, 0, 0),\n",
            "    alpha: float = 0.5, \n",
            "    resize = (256, 256)\n",
            ") -> np.ndarray:\n",
            "    \"\"\"Combines image and its segmentation mask into a single image.\n",
            "    \n",
            "    Params:\n",
            "        image: Training image.\n",
            "        mask: Segmentation mask.\n",
            "        color: Color for segmentation mask rendering.\n",
            "        alpha: Segmentation mask's transparency.\n",
            "        resize: If provided, both image and its mask are resized before blending them together.\n",
            "    \n",
            "    Returns:\n",
            "        image_combined: The combined image.\n",
            "        \n",
            "    \"\"\"\n",
            "    color = np.asarray(color).reshape(1, 1, 3)\n",
            "    colored_mask = np.expand_dims(mask, 0).repeat(3, axis=2)\n",
            "    masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n",
            "    image_overlay = masked.filled()\n",
            "    \n",
            "    if resize is not None:\n",
            "        image = cv2.resize(image, resize)\n",
            "        image_overlay = cv2.resize(image_overlay, resize)\n",
            "    \n",
            "    image_combined = cv2.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n",
            "    \n",
            "    return image_combined\n",
            "\n",
            "def inference(model, bytesImg, dim, unit):\n",
            "    #print(img_path) \n",
            "    \n",
            "    image = read_image(bytesImg) #Read Array\n",
            "    # batchify\n",
            "    image = image.unsqueeze(0)\n",
            "    # hacky way to pass ground truth label\n",
            "    model.set_input({'image': image, 'label': torch.zeros_like(image), 'A_paths':''}) \n",
            "    model.test()           # run inference\n",
            "    visuals = model.get_current_visuals()  # get image results\n",
            "    confidence = visuals['fused'].max()\n",
            "\n",
            "    # fused for final prediction\n",
            "    for key in visuals.keys():\n",
            "        visuals[key] = tensor2im(visuals[key])\n",
            "        \n",
            "    h, w, _ = visuals['fused'].shape\n",
            "    fused = Image.fromarray(visuals['fused'])\n",
            "    fused = np.array(fused, dtype='uint8')\n",
            "    realHeight=dim[1]\n",
            "    realWidth=dim[0]\n",
            "\n",
            "    mask = cv2.cvtColor(fused, cv2.COLOR_BGR2GRAY)\n",
            "    mask[mask < 90] = 0\n",
            "    mask[mask >= 90] = 255\n",
            "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL,\n",
            "                            cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "    \n",
            "    overlay_img = overlay(tensor2im(image), mask, alpha=0)\n",
            "    cv2.drawContours(image=overlay_img, contours=cnts[0], contourIdx=-1, color=(0, 255, 0), thickness=1, lineType=cv2.LINE_AA)\n",
            "    contour_img = getContours(fused, overlay_img, realHeight, realWidth, unit, confidence)\n",
            "\n",
            "    return contour_img if contour_img is not None else overlay_img, visuals\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "id": "l_T7BUVidPRY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inference_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNZG79OgdQkp",
        "outputId": "56a46fda-8d27-4e0e-d42e-ab7ffee149b1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "V2QzVlXu_WGD"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from inference_utils import inference, create_model\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel\n",
        "from fastapi import UploadFile, File\n",
        "import io\n",
        "from starlette.responses import StreamingResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import base64\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Parameters(BaseModel):\n",
        "    input_nc: int = 3\n",
        "    output_nc: int = 3\n",
        "    ngf: int = 64\n",
        "    ndf: int = 64\n",
        "    netG:str = 'resnet_9blocks'\n",
        "    norm: str = 'instance'\n",
        "    init_type: str = 'xavier'\n",
        "    init_gain: float = 0.02\n",
        "    display_sides: int = 1\n",
        "    num_classes: int = 1\n",
        "    gpu_ids: List[int] = [0]\n",
        "    isTrain: bool = False"
      ],
      "metadata": {
        "id": "cJ3f7cFEbkm2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "origins = [\"*\"]\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ],
      "metadata": {
        "id": "BUDT1DDLhOS5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"Hello\": \"World\"}\n",
        "\n",
        "def from_image_to_bytes(img):\n",
        "    \"\"\"\n",
        "    pillow image to bytes\n",
        "    \"\"\"\n",
        "    imgByteArr = io.BytesIO()\n",
        "    img.save(imgByteArr, format='png')\n",
        "    imgByteArr = imgByteArr.getvalue()\n",
        "\n",
        "    encoded = base64.b64encode(imgByteArr)\n",
        "    decoded = encoded.decode('ascii')\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "wRbr2HcFhWpe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/predict/{dim}/{unit}\")\n",
        "async def predict(dim:str, unit:str, file: UploadFile = File(...)):\n",
        "    bytesImg = await file.read()\n",
        "    width, height = [float(x) for x in dim.split('-')]    \n",
        "    parameters = Parameters()\n",
        "    model = create_model(parameters)\n",
        "    predicted_cntr, visuals = inference(model, bytesImg, (width, height), unit) # Outputs Predicted Masks\n",
        "\n",
        "    cntr_converted = from_image_to_bytes(Image.fromarray(predicted_cntr))\n",
        "    \n",
        "    img_list = [cntr_converted]\n",
        "    \n",
        "    for k in ['fused', 'side1', 'side2', 'side3', 'side4', 'side5']:\n",
        "        map_ = from_image_to_bytes(Image.fromarray(visuals[k]))\n",
        "        img_list.append(map_)\n",
        "    return img_list\n"
      ],
      "metadata": {
        "id": "yZ5f5RQQhcf3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiSJtmeXiKxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}